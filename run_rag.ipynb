{
 "cells": [
  {
   "cell_type": "code",
   "id": "7baf2735-58c3-4831-9de4-b503e53ea537",
   "metadata": {},
   "source": [
    "!pip uninstall -y tensorboard tensorboard-data-server tensorboard-plugin-wit tensorflow tensorflow-estimator tensorflow-io-gcs-filesystem \n",
    "!pip uninstall -y nvidia-cublas-cu11 nvidia-cublas-cu12 nvidia-cuda-cupti-cu11 nvidia-cuda-cupti-cu12 nvidia-cuda-nvrtc-cu11 nvidia-cuda-nvrtc-cu12 nvidia-cuda-runtime-cu11 nvidia-cuda-runtime-cu12 nvidia-cudnn-cu11 nvidia-cudnn-cu12 nvidia-cufft-cu11 nvidia-cufft-cu12 nvidia-curand-cu11 nvidia-curand-cu12 nvidia-cusolver-cu11 nvidia-cusolver-cu12 nvidia-cusparse-cu11 nvidia-cusparse-cu12 nvidia-nccl-cu11 nvidia-nccl-cu12 nvidia-nvjitlink-cu12 nvidia-nvtx-cu11 nvidia-nvtx-cu12   \n",
    "!pip uninstall -y langchain langchain-core langchain-google-genai langchain-openai langchain-text-splitters langchainhub "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c011e9ff",
   "metadata": {
    "tags": []
   },
   "source": [
    "!pip install --user -r \"retrieval_augmented_generation/requirements.txt\"\n",
    "#!pip install torch~=2.2.1\n",
    "#!pip install bitsandbytes~=0.43\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install './to install before use/bitsandbytes-0.44.0.dev0-cp310-cp310-win_amd64.whl'"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "eeef8d4c",
   "metadata": {},
   "source": "check if installation was successful:"
  },
  {
   "cell_type": "code",
   "id": "5620dd5c",
   "metadata": {
    "tags": []
   },
   "source": [
    "import torch\n",
    "print(\"CUDA version: \", torch.version.cuda)\n",
    "!python -m bitsandbytes"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Example initialization with model from Hugging Face Hub\n",
    "\n",
    "insert own Hugging Face Hub API key if necessary."
   ],
   "id": "3de9a4834424ac02"
  },
  {
   "cell_type": "code",
   "id": "e3cafc59",
   "metadata": {
    "tags": [],
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "from retrieval_augmented_generation.rag import RAG\n",
    "from retrieval_augmented_generation.configs import TextGenerationConfig, RetrievalConfig\n",
    "\n",
    "\n",
    "rag = RAG('../Dokumente')\n",
    "\n",
    "retrieval_config = RetrievalConfig(\n",
    "    embedding_model_name=\"intfloat/multilingual-e5-base\",\n",
    "    embedding_query_template=\"{text}\",\n",
    "    retrieval_query_template=\"query:{question}\"\n",
    ")\n",
    "\n",
    "text_generation_config = TextGenerationConfig(\n",
    "    text_generation_model_name=\"google/gemma-1.1-2b-it\",\n",
    ")\n",
    "rag.init_huggingface(\n",
    "    hf_transformers_cache_dir=\"./../../hf_transformers_cache\",\n",
    "    hf_hub_api_key=\"hf_XXXXXX\",\n",
    "    retrieval_config=retrieval_config,\n",
    "    text_generation_config=text_generation_config\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e1ea059b",
   "metadata": {
    "tags": [],
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "while True:\n",
    "    question = input(\"\\nQuestion::\\n\")\n",
    "    answer = rag.ask(question)\n",
    "    \n",
    "    print(\"Answer:\")\n",
    "    print(answer['answer'], \"\\n\")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
